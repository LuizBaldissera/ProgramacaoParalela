# -*- coding: utf-8 -*-
"""MPI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1P6VA5ZJP6xsKN1wHGUN7OsethQJXkh5V
"""

!sudo apt-get update
!sudo apt-get install openmpi-bin openmpi-common libopenmpi-dev -y

# Commented out IPython magic to ensure Python compatibility.
# %%writefile mpi_hello_world.c
# #include <stdio.h>
# #include <stdlib.h>
# #include <mpi.h>
# 
# int main(int argc, char** argv) {
#     int rank, size;
#     MPI_Init(&argc, &argv);
#     MPI_Comm_rank(MPI_COMM_WORLD, &rank);
#     MPI_Comm_size(MPI_COMM_WORLD, &size);
# 
#     int n;
#     if (rank == 0) {
#         if (argc > 1) {
#             n = atoi(argv[1]);
#         } else {
#             n = 1000;
#         }
#     }
# 
#     MPI_Bcast(&n, 1, MPI_INT, 0, MPI_COMM_WORLD);
# 
#     int base = n / size;
#     int resto = n % size;
#     int linhas_local = base + (rank < resto ? 1 : 0);
# 
#     int *sendcounts = NULL, *displs = NULL;
#     if (rank == 0) {
#         sendcounts = malloc(size * sizeof(int));
#         displs = malloc(size * sizeof(int));
#         int offset = 0;
#         for (int i = 0; i < size; i++) {
#             int linhas = base + (i < resto ? 1 : 0);
#             sendcounts[i] = linhas * n;
#             displs[i] = offset;
#             offset += sendcounts[i];
#         }
#     }
# 
#     double *A = NULL, *B = NULL, *C = NULL;
#     double *subA = malloc(linhas_local * n * sizeof(double));
#     double *subB = malloc(linhas_local * n * sizeof(double));
#     double *subC = malloc(linhas_local * n * sizeof(double));
# 
#     if (rank == 0) {
#         A = malloc(n * n * sizeof(double));
#         B = malloc(n * n * sizeof(double));
#         C = malloc(n * n * sizeof(double));
#         for (int i = 0; i < n * n; i++) {
#             A[i] = rand() % 10;
#             B[i] = rand() % 10;
#         }
#     }
# 
#     MPI_Barrier(MPI_COMM_WORLD);
#     double start = MPI_Wtime();
# 
#     MPI_Scatterv(A, sendcounts, displs, MPI_DOUBLE,
#                  subA, linhas_local * n, MPI_DOUBLE, 0, MPI_COMM_WORLD);
#     MPI_Scatterv(B, sendcounts, displs, MPI_DOUBLE,
#                  subB, linhas_local * n, MPI_DOUBLE, 0, MPI_COMM_WORLD);
# 
#     for (int i = 0; i < linhas_local * n; i++)
#         subC[i] = subA[i] + subB[i];
# 
#     MPI_Gatherv(subC, linhas_local * n, MPI_DOUBLE,
#                 C, sendcounts, displs, MPI_DOUBLE, 0, MPI_COMM_WORLD);
# 
#     MPI_Barrier(MPI_COMM_WORLD);
#     double end = MPI_Wtime();
# 
#     if (rank == 0) {
#         printf("Tempo total (soma): %.6f segundos\n", end - start);
#         free(A); free(B); free(C); free(sendcounts); free(displs);
#     }
# 
#     free(subA); free(subB); free(subC);
#     MPI_Finalize();
#     return 0;
# }

!mpicc mpi_hello_world.c -o mpi_hello_world_arg
!ls -l mpi_hello_world_arg

# Commented out IPython magic to ensure Python compatibility.
# %%writefile maior_valor.c
# #include <stdio.h>
# #include <stdlib.h>
# #include <mpi.h>
# 
# int main(int argc, char** argv) {
#     int rank, size;
#     MPI_Init(&argc, &argv);
#     MPI_Comm_rank(MPI_COMM_WORLD, &rank);
#     MPI_Comm_size(MPI_COMM_WORLD, &size);
# 
#     int n;
#     if (rank == 0) {
#         if (argc > 1) {
#             n = atoi(argv[1]);
#         } else {
#             n = 1000;
#         }
#     }
# 
#     MPI_Bcast(&n, 1, MPI_INT, 0, MPI_COMM_WORLD);
# 
#     int base = n / size;
#     int resto = n % size;
#     int linhas_local = base + (rank < resto ? 1 : 0);
# 
#     int *sendcounts = NULL, *displs = NULL;
#     if (rank == 0) {
#         sendcounts = malloc(size * sizeof(int));
#         displs = malloc(size * sizeof(int));
#         int offset = 0;
#         for (int i = 0; i < size; i++) {
#             int linhas = base + (i < resto ? 1 : 0);
#             sendcounts[i] = linhas * n;
#             displs[i] = offset;
#             offset += sendcounts[i];
#         }
#     }
# 
#     double *A = NULL, *B = NULL, *C = NULL;
#     double *subA = malloc(linhas_local * n * sizeof(double));
#     double *subB = malloc(linhas_local * n * sizeof(double));
#     double *subC = malloc(linhas_local * n * sizeof(double));
# 
#     if (rank == 0) {
#         A = malloc(n * n * sizeof(double));
#         B = malloc(n * n * sizeof(double));
#         C = malloc(n * n * sizeof(double));
#         for (int i = 0; i < n * n; i++) {
#             A[i] = rand() % 10;
#             B[i] = rand() % 10;
#         }
#     }
# 
#     MPI_Barrier(MPI_COMM_WORLD);
#     double start = MPI_Wtime();
# 
#     MPI_Scatterv(A, sendcounts, displs, MPI_DOUBLE,
#                  subA, linhas_local * n, MPI_DOUBLE, 0, MPI_COMM_WORLD);
#     MPI_Scatterv(B, sendcounts, displs, MPI_DOUBLE,
#                  subB, linhas_local * n, MPI_DOUBLE, 0, MPI_COMM_WORLD);
# 
#     for (int i = 0; i < linhas_local * n; i++)
#         subC[i] = subA[i] + subB[i];
# 
#     MPI_Gatherv(subC, linhas_local * n, MPI_DOUBLE,
#                 C, sendcounts, displs, MPI_DOUBLE, 0, MPI_COMM_WORLD);
# 
#     MPI_Barrier(MPI_COMM_WORLD);
#     double end = MPI_Wtime();
# 
#     if (rank == 0) {
#         printf("Tempo total (soma): %.6f segundos\n", end - start);
#         free(A); free(B); free(C); free(sendcounts); free(displs);
#     }
# 
#     free(subA); free(subB); free(subC);
#     MPI_Finalize();
#     return 0;
# }

!mpicc maior_valor.c -o maior_valor_arg
!ls -l maior_valor_arg

# Commented out IPython magic to ensure Python compatibility.
# %%writefile vetor_matriz.c
# #include <stdio.h>
# #include <stdlib.h>
# #include <mpi.h>
# 
# int main(int argc, char** argv) {
#     int rank, size;
#     MPI_Init(&argc, &argv);
#     MPI_Comm_rank(MPI_COMM_WORLD, &rank);
#     MPI_Comm_size(MPI_COMM_WORLD, &size);
# 
#     int n;
#     if (rank == 0) {
#         if (argc > 1) {
#             n = atoi(argv[1]);
#         } else {
#             n = 1000;
#         }
#     }
# 
#     MPI_Bcast(&n, 1, MPI_INT, 0, MPI_COMM_WORLD);
# 
#     int base = n / size;
#     int resto = n % size;
#     int linhas_local = base + (rank < resto ? 1 : 0);
# 
#     int *sendcounts = NULL, *displs = NULL;
#     if (rank == 0) {
#         sendcounts = malloc(size * sizeof(int));
#         displs = malloc(size * sizeof(int));
#         int offset = 0;
#         for (int i = 0; i < size; i++) {
#             int linhas = base + (i < resto ? 1 : 0);
#             sendcounts[i] = linhas * n;
#             displs[i] = offset;
#             offset += sendcounts[i];
#         }
#     }
# 
#     double *A = NULL, *v = NULL, *r = NULL;
#     double *subA = malloc(linhas_local * n * sizeof(double));
#     double *subR = malloc(linhas_local * sizeof(double));
# 
#     if (rank == 0) {
#         A = malloc(n * n * sizeof(double));
#         v = malloc(n * sizeof(double));
#         r = malloc(n * sizeof(double));
#         for (int i = 0; i < n * n; i++) A[i] = rand() % 10;
#         for (int i = 0; i < n; i++) v[i] = rand() % 10;
#     } else {
#         v = malloc(n * sizeof(double));
#     }
# 
#     MPI_Bcast(v, n, MPI_DOUBLE, 0, MPI_COMM_WORLD);
# 
#     MPI_Barrier(MPI_COMM_WORLD);
#     double start = MPI_Wtime();
# 
#     MPI_Scatterv(A, sendcounts, displs, MPI_DOUBLE,
#                  subA, linhas_local * n, MPI_DOUBLE, 0, MPI_COMM_WORLD);
# 
#     for (int i = 0; i < linhas_local; i++) {
#         subR[i] = 0;
#         for (int j = 0; j < n; j++)
#             subR[i] += subA[i * n + j] * v[j];
#     }
# 
#     int *recvcounts = NULL, *recvdispls = NULL;
#     if (rank == 0) {
#         recvcounts = malloc(size * sizeof(int));
#         recvdispls = malloc(size * sizeof(int));
#         int offset = 0;
#         for (int i = 0; i < size; i++) {
#             int linhas = base + (i < resto ? 1 : 0);
#             recvcounts[i] = linhas;
#             recvdispls[i] = offset;
#             offset += linhas;
#         }
#     }
# 
#     MPI_Gatherv(subR, linhas_local, MPI_DOUBLE,
#                 r, recvcounts, recvdispls, MPI_DOUBLE, 0, MPI_COMM_WORLD);
# 
#     MPI_Barrier(MPI_COMM_WORLD);
#     double end = MPI_Wtime();
# 
#     if (rank == 0) {
#         printf("Tempo total (vetor x matriz): %.6f segundos\n", end - start);
#         free(A); free(v); free(r);
#         free(sendcounts); free(displs);
#         free(recvcounts); free(recvdispls);
#     } else {
#         free(v);
#     }
# 
#     free(subA); free(subR);
#     MPI_Finalize();
#     return 0;
# }

!mpicc vetor_matriz.c -o vetor_matriz_arg
!ls -l vetor_matriz_arg

# Commented out IPython magic to ensure Python compatibility.
# %%writefile run_experiments.sh
# #!/bin/bash
# 
# ns=(100 1000 10000)
# procs=(2 4 6)
# executables=("mpi_hello_world_arg" "maior_valor_arg" "vetor_matriz_arg")
# 
# echo "Executable,n,processes,time" > results.csv
# 
# for exec in "${executables[@]}"; do
#   for n_val in "${ns[@]}"; do
#     for p_val in "${procs[@]}"; do
#       echo "Running $exec with n=$n_val and $p_val processes..."
#       output=$(mpirun --allow-run-as-root --oversubscribe -np $p_val ./$exec $n_val)
#       time=$(echo "$output" | grep -i "tempo" | grep -Eo "[0-9]+\.[0-9]+")
#       echo "$exec,$n_val,$p_val,$time" >> results.csv
#     done
#   done
# done
# 
# echo "Experimentation complete. Results saved to results.csv"

!chmod +x run_experiments.sh
!./run_experiments.sh

!cat results.csv

import pandas as pd

df = pd.read_csv('results.csv')

display(df.head())
display(df.info())

df_n100 = df[df['n'] == 100].pivot(index='processes', columns='Executable', values='time')
df_n1000 = df[df['n'] == 1000].pivot(index='processes', columns='Executable', values='time')
df_n10000 = df[df['n'] == 10000].pivot(index='processes', columns='Executable', values='time')

display(df_n100)
display(df_n1000)
display(df_n10000)

import matplotlib.pyplot as plt


df_n100_pivot = df_n100.T
df_n1000_pivot = df_n1000.T


plt.figure(figsize=(12, 6))
df_n100_pivot.plot(kind='bar', ax=plt.gca())
plt.title('Tempo de Execução para n=100')
plt.xlabel('Executável')
plt.ylabel('Tempo (segundos)')
plt.xticks(rotation=0)
plt.grid(axis='y')
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt

plt.figure(figsize=(12, 6))
df_n1000_pivot.plot(kind='bar', ax=plt.gca())
plt.title('Tempo de Execução para n=1000')
plt.xlabel('Executável')
plt.ylabel('Tempo (segundos)')
plt.xticks(rotation=0)
plt.grid(axis='y')
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt

# Pivot the data to have Executable on index and processes as columns
df_n10000_pivot = df_n10000.T


plt.figure(figsize=(12, 6))
df_n10000_pivot.plot(kind='bar', ax=plt.gca())
plt.title('Tempo de Execução para n=10000')
plt.xlabel('Executável')
plt.ylabel('Tempo (segundos)')
plt.xticks(rotation=0)
plt.grid(axis='y')
plt.tight_layout()
plt.show()